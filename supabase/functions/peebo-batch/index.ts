// Peebo Batch Apply Edge Function
// Handles bulk job application sessions with job scraping and sequential applications

import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

// Types
interface BatchSession {
  id: string
  status: 'setup' | 'scraping' | 'active' | 'complete' | 'stopped'
  created_at: string
  started_at: string | null
  completed_at: string | null
  config: {
    target_count: number
    criteria_summary: string
    resume_name: string
  }
  jobs: BatchJob[]
  total_cost: number
  completed_count: number
  failed_count: number
}

interface BatchJob {
  id: string
  position: number
  company: string
  role: string
  job_url: string
  status: 'queued' | 'running' | 'success' | 'failed' | 'stopped'
  browser_use_task_id: string | null
  live_url: string | null
  started_at: string | null
  completed_at: string | null
  current_step: string | null
  agent_success: boolean | null
  email_verified: boolean
  error_message: string | null
  cost: number
  tracker_job_id: string | null
  job_description: string | null
  tailored_resume: string | null
}

interface StartBatchRequest {
  target_count: number
  criteria: {
    target_roles: string[]
    location?: string
    salary_min?: number
    industries?: string[]
  }
  resume_text: string
  user_info: {
    name: string
    email: string
    phone?: string
    linkedin?: string
  }
}

interface PeeboUser {
  id: string
  auth_user_id: string
  email: string
  tier: 'free' | 'premium'
  monthly_app_limit: number
  apps_used_this_month: number
  full_name?: string
  resume_text?: string
  linkedin_url?: string
  target_roles?: string[]
}

// In-memory session store (in production, use Supabase table)
const sessions = new Map<string, BatchSession>()

// Generate UUID
function generateUUID(): string {
  return crypto.randomUUID()
}

// Main handler
Deno.serve(async (req) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  const url = new URL(req.url)
  const path = url.pathname.replace('/peebo-batch', '')

  try {
    // Get auth header
    const authHeader = req.headers.get('Authorization')
    if (!authHeader) {
      return jsonResponse({ error: 'Missing authorization header' }, 401)
    }

    // Initialize Supabase client
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!
    const supabaseAnonKey = Deno.env.get('SUPABASE_ANON_KEY')!
    const supabase = createClient(supabaseUrl, supabaseAnonKey, {
      global: { headers: { Authorization: authHeader } }
    })

    // Get authenticated user
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    if (authError || !user) {
      return jsonResponse({ error: 'Unauthorized' }, 401)
    }

    // Get Peebo user
    const { data: peeboUser, error: userError } = await supabase
      .from('peebo_users')
      .select('*')
      .eq('auth_user_id', user.id)
      .single()

    if (userError || !peeboUser) {
      return jsonResponse({ error: 'User profile not found' }, 404)
    }

    // Route requests
    if (req.method === 'POST' && path === '/start') {
      return handleStartBatch(req, supabase, peeboUser as PeeboUser)
    }

    if (req.method === 'GET' && path.match(/^\/[^/]+\/status$/)) {
      const sessionId = path.split('/')[1]
      return handleGetStatus(sessionId, peeboUser as PeeboUser)
    }

    if (req.method === 'POST' && path.match(/^\/[^/]+\/stop$/)) {
      const sessionId = path.split('/')[1]
      return handleStopBatch(sessionId, peeboUser as PeeboUser)
    }

    if (req.method === 'POST' && path.match(/^\/[^/]+\/job\/[^/]+\/stop$/)) {
      const parts = path.split('/')
      const sessionId = parts[1]
      const jobId = parts[3]
      return handleStopJob(sessionId, jobId, peeboUser as PeeboUser)
    }

    if (req.method === 'POST' && path.match(/^\/[^/]+\/job\/[^/]+\/retry$/)) {
      const parts = path.split('/')
      const sessionId = parts[1]
      const jobId = parts[3]
      return handleRetryJob(sessionId, jobId, supabase, peeboUser as PeeboUser)
    }

    return jsonResponse({ error: 'Not found' }, 404)

  } catch (error) {
    console.error('Peebo batch error:', error)
    return jsonResponse({ error: error.message || 'Internal server error' }, 500)
  }
})

// Helper for JSON responses
function jsonResponse(data: unknown, status = 200) {
  return new Response(JSON.stringify(data), {
    status,
    headers: { ...corsHeaders, 'Content-Type': 'application/json' }
  })
}

// Start a new batch session
async function handleStartBatch(
  req: Request,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser
): Promise<Response> {
  const body = await req.json() as StartBatchRequest

  // Validate
  if (!body.target_count || body.target_count < 1 || body.target_count > 20) {
    return jsonResponse({ error: 'target_count must be between 1 and 20' }, 400)
  }

  // Check user has enough applications remaining
  const { data: remaining } = await supabase
    .rpc('peebo_remaining_apps', { p_user_id: user.id })

  if (remaining !== null && remaining < body.target_count) {
    return jsonResponse({
      error: `You only have ${remaining} applications remaining this month`,
      remaining
    }, 429)
  }

  // Create session
  const sessionId = generateUUID()
  const session: BatchSession = {
    id: sessionId,
    status: 'scraping',
    created_at: new Date().toISOString(),
    started_at: new Date().toISOString(),
    completed_at: null,
    config: {
      target_count: body.target_count,
      criteria_summary: formatCriteriaSummary(body.criteria),
      resume_name: 'resume_optimized.txt'
    },
    jobs: [],
    total_cost: 0,
    completed_count: 0,
    failed_count: 0
  }

  sessions.set(sessionId, session)

  // Start job scraping in background
  startJobScraping(sessionId, body, supabase, user)

  // Log session start
  await supabase.from('peebo_usage_logs').insert({
    user_id: user.id,
    action: 'batch_started',
    metadata: {
      session_id: sessionId,
      target_count: body.target_count,
      criteria: body.criteria
    }
  })

  return jsonResponse({
    session_id: sessionId,
    status: 'scraping',
    message: 'Batch session started, searching for jobs...'
  })
}

// Get batch status
function handleGetStatus(sessionId: string, user: PeeboUser): Response {
  const session = sessions.get(sessionId)
  if (!session) {
    return jsonResponse({ error: 'Session not found' }, 404)
  }

  const summary = {
    total: session.jobs.length,
    completed: session.jobs.filter(j => j.status === 'success').length,
    failed: session.jobs.filter(j => j.status === 'failed').length,
    running: session.jobs.filter(j => j.status === 'running').length,
    queued: session.jobs.filter(j => j.status === 'queued').length,
    stopped: session.jobs.filter(j => j.status === 'stopped').length,
    total_cost: session.total_cost
  }

  return jsonResponse({
    session_id: session.id,
    status: session.status,
    jobs: session.jobs,
    summary,
    config: session.config
  })
}

// Stop entire batch
function handleStopBatch(sessionId: string, user: PeeboUser): Response {
  const session = sessions.get(sessionId)
  if (!session) {
    return jsonResponse({ error: 'Session not found' }, 404)
  }

  // Stop all queued jobs
  session.jobs.forEach(job => {
    if (job.status === 'queued') {
      job.status = 'stopped'
    }
  })

  session.status = 'stopped'
  session.completed_at = new Date().toISOString()

  return jsonResponse({
    success: true,
    message: 'Batch stopped'
  })
}

// Stop specific job
function handleStopJob(sessionId: string, jobId: string, user: PeeboUser): Response {
  const session = sessions.get(sessionId)
  if (!session) {
    return jsonResponse({ error: 'Session not found' }, 404)
  }

  const job = session.jobs.find(j => j.id === jobId)
  if (!job) {
    return jsonResponse({ error: 'Job not found' }, 404)
  }

  if (job.status === 'queued' || job.status === 'running') {
    job.status = 'stopped'
    // TODO: Cancel browser-use task if running
  }

  return jsonResponse({
    success: true,
    message: 'Job stopped'
  })
}

// Retry failed job
async function handleRetryJob(
  sessionId: string,
  jobId: string,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser
): Promise<Response> {
  const session = sessions.get(sessionId)
  if (!session) {
    return jsonResponse({ error: 'Session not found' }, 404)
  }

  const job = session.jobs.find(j => j.id === jobId)
  if (!job) {
    return jsonResponse({ error: 'Job not found' }, 404)
  }

  if (job.status !== 'failed') {
    return jsonResponse({ error: 'Can only retry failed jobs' }, 400)
  }

  // Reset job status
  job.status = 'queued'
  job.error_message = null
  job.started_at = null
  job.completed_at = null

  // Trigger processing
  processNextJob(session, supabase, user)

  return jsonResponse({
    success: true,
    message: 'Job queued for retry'
  })
}

// Format criteria summary for display
function formatCriteriaSummary(criteria: StartBatchRequest['criteria']): string {
  const parts = []
  if (criteria.target_roles?.length) {
    parts.push(`Roles: ${criteria.target_roles.join(', ')}`)
  }
  if (criteria.location) {
    parts.push(`Location: ${criteria.location}`)
  }
  if (criteria.salary_min) {
    parts.push(`Salary: $${Math.round(criteria.salary_min / 1000)}k+`)
  }
  if (criteria.industries?.length) {
    parts.push(`Industries: ${criteria.industries.join(', ')}`)
  }
  return parts.join(' â€¢ ')
}

// Start job scraping (runs in background)
async function startJobScraping(
  sessionId: string,
  request: StartBatchRequest,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser
) {
  const session = sessions.get(sessionId)
  if (!session) return

  try {
    const browserUseKey = Deno.env.get('PEEBO_BROWSER_USE_KEY')
    if (!browserUseKey) {
      throw new Error('Browser-use API key not configured')
    }

    // Build scraper task
    const scraperTask = buildScraperTask(request)

    // Start browser-use task
    const response = await fetch('https://api.browser-use.com/api/v1/run-task', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${browserUseKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        task: scraperTask,
        save_browser_data: true
      })
    })

    if (!response.ok) {
      throw new Error('Failed to start job scraper')
    }

    const result = await response.json()

    // Poll for scraper results
    await pollScraperResults(sessionId, result.id, browserUseKey, request, supabase, user)

  } catch (error) {
    console.error('Job scraping error:', error)
    session.status = 'stopped'
    session.completed_at = new Date().toISOString()
  }
}

// Build the scraper task for browser-use
function buildScraperTask(request: StartBatchRequest): string {
  const roles = request.criteria.target_roles?.join(', ') || 'Software Engineer'
  const location = request.criteria.location || 'Remote'

  return `
Search for ${request.target_count} job postings that match these criteria:
- Roles: ${roles}
- Location: ${location}
${request.criteria.salary_min ? `- Minimum salary: $${request.criteria.salary_min}` : ''}
${request.criteria.industries?.length ? `- Industries: ${request.criteria.industries.join(', ')}` : ''}

Search on LinkedIn Jobs, Indeed, and company career pages.
Skip "Easy Apply" jobs on LinkedIn (we want direct applications).
Skip jobs that require login to view.

For each job found, extract:
1. Company name
2. Job title/role
3. Direct application URL (not the search result URL)

Return the results as a JSON array with this format:
[
  {"company": "Acme Corp", "role": "Senior Product Manager", "url": "https://..."},
  ...
]

Important:
- Only include jobs with direct apply links (not "Easy Apply")
- Verify each URL leads to an actual application form
- Stop once you have ${request.target_count} valid jobs
`.trim()
}

// Poll for scraper results and start applications
async function pollScraperResults(
  sessionId: string,
  taskId: string,
  apiKey: string,
  request: StartBatchRequest,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser
) {
  const session = sessions.get(sessionId)
  if (!session) return

  const maxPolls = 60 // 5 minutes max
  let polls = 0

  while (polls < maxPolls) {
    await new Promise(resolve => setTimeout(resolve, 5000)) // Poll every 5 seconds
    polls++

    try {
      const response = await fetch(`https://api.browser-use.com/api/v1/task/${taskId}`, {
        headers: { 'Authorization': `Bearer ${apiKey}` }
      })

      if (!response.ok) continue

      const result = await response.json()

      if (result.status === 'completed') {
        // Parse jobs from result
        const jobs = parseScraperResults(result.output, request.target_count)

        if (jobs.length === 0) {
          session.status = 'stopped'
          session.completed_at = new Date().toISOString()
          return
        }

        // Create batch jobs
        session.jobs = jobs.map((job, index) => ({
          id: generateUUID(),
          position: index + 1,
          company: job.company,
          role: job.role,
          job_url: job.url,
          status: 'queued' as const,
          browser_use_task_id: null,
          live_url: null,
          started_at: null,
          completed_at: null,
          current_step: null,
          agent_success: null,
          email_verified: false,
          error_message: null,
          cost: 0,
          tracker_job_id: null,
          job_description: null,
          tailored_resume: null
        }))

        session.status = 'active'

        // Start processing jobs
        processNextJob(session, supabase, user, request)
        return
      }

      if (result.status === 'failed') {
        session.status = 'stopped'
        session.completed_at = new Date().toISOString()
        return
      }
    } catch (error) {
      console.error('Polling error:', error)
    }
  }

  // Timeout
  session.status = 'stopped'
  session.completed_at = new Date().toISOString()
}

// Parse scraper output into job list
function parseScraperResults(output: string, maxJobs: number): Array<{ company: string; role: string; url: string }> {
  try {
    // Try to find JSON array in output
    const jsonMatch = output.match(/\[[\s\S]*\]/)
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0])
      if (Array.isArray(parsed)) {
        return parsed.slice(0, maxJobs).filter(job =>
          job.company && job.role && job.url
        )
      }
    }
  } catch (e) {
    console.error('Failed to parse scraper results:', e)
  }
  return []
}

// Fetch job description using browser-use
async function fetchJobDescription(jobUrl: string, apiKey: string): Promise<string> {
  try {
    const task = `
Navigate to ${jobUrl} and extract the full job description.

Return ONLY the job description text including:
- Job title and company
- Responsibilities/duties
- Requirements/qualifications
- Skills required
- Any other relevant details

Format the output as plain text, not JSON.
`.trim()

    const response = await fetch('https://api.browser-use.com/api/v1/run-task', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        task,
        save_browser_data: false
      })
    })

    if (!response.ok) {
      throw new Error('Failed to start job description fetch')
    }

    const result = await response.json()
    const taskId = result.id

    // Poll for completion (max 2 minutes)
    for (let i = 0; i < 24; i++) {
      await new Promise(resolve => setTimeout(resolve, 5000))

      const statusResponse = await fetch(`https://api.browser-use.com/api/v1/task/${taskId}`, {
        headers: { 'Authorization': `Bearer ${apiKey}` }
      })

      if (!statusResponse.ok) continue

      const statusResult = await statusResponse.json()

      if (statusResult.status === 'completed') {
        return statusResult.output || ''
      }

      if (statusResult.status === 'failed') {
        throw new Error(statusResult.error || 'Failed to fetch job description')
      }
    }

    throw new Error('Job description fetch timed out')
  } catch (error) {
    console.error('Error fetching job description:', error)
    return ''
  }
}

// Tailor resume for a specific job using OpenRouter
async function tailorResumeForJob(
  baseResume: string,
  jobDescription: string,
  jobRole: string,
  company: string
): Promise<string> {
  const openrouterKey = Deno.env.get('OPENROUTER_API_KEY')
  if (!openrouterKey) {
    console.log('OpenRouter API key not configured, using base resume')
    return baseResume
  }

  if (!jobDescription || jobDescription.length < 100) {
    console.log('Job description too short, using base resume')
    return baseResume
  }

  try {
    const prompt = `You are an expert ATS (Applicant Tracking System) resume optimizer.

Given the applicant's base resume and a job description, create a tailored version of the resume that:
1. Incorporates relevant keywords from the job description naturally
2. Highlights experiences that match what the job is looking for
3. Reorders or emphasizes skills that are most relevant to this specific role
4. Keeps all factual information accurate - do not fabricate experiences
5. Maintains a professional tone

JOB: ${jobRole} at ${company}

JOB DESCRIPTION:
${jobDescription.substring(0, 3000)}

BASE RESUME:
${baseResume.substring(0, 4000)}

OUTPUT ONLY the optimized resume text. No explanations, no markdown formatting, just the resume content ready to paste into an application form.`

    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openrouterKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://peebo.app',
        'X-Title': 'Peebo Job Application'
      },
      body: JSON.stringify({
        model: 'google/gemini-2.0-flash-001',
        messages: [
          { role: 'user', content: prompt }
        ],
        max_tokens: 2000,
        temperature: 0.3
      })
    })

    if (!response.ok) {
      const error = await response.text()
      console.error('OpenRouter error:', error)
      return baseResume
    }

    const result = await response.json()
    const tailoredResume = result.choices?.[0]?.message?.content?.trim()

    if (tailoredResume && tailoredResume.length > 200) {
      console.log(`Resume tailored for ${company} - ${jobRole}`)
      return tailoredResume
    }

    return baseResume
  } catch (error) {
    console.error('Error tailoring resume:', error)
    return baseResume
  }
}

// Process the next queued job
async function processNextJob(
  session: BatchSession,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser,
  request?: StartBatchRequest
) {
  // Find next queued job
  const nextJob = session.jobs.find(j => j.status === 'queued')
  if (!nextJob) {
    // Check if all jobs are done
    const allDone = session.jobs.every(j =>
      j.status === 'success' || j.status === 'failed' || j.status === 'stopped'
    )
    if (allDone) {
      session.status = 'complete'
      session.completed_at = new Date().toISOString()
      session.completed_count = session.jobs.filter(j => j.status === 'success').length
      session.failed_count = session.jobs.filter(j => j.status === 'failed').length
    }
    return
  }

  // Check if another job is already running
  const runningJob = session.jobs.find(j => j.status === 'running')
  if (runningJob) return

  // Start this job
  nextJob.status = 'running'
  nextJob.started_at = new Date().toISOString()
  nextJob.current_step = 'Fetching job description...'

  try {
    const browserUseKey = Deno.env.get('PEEBO_BROWSER_USE_KEY')
    if (!browserUseKey) {
      throw new Error('Browser-use API key not configured')
    }

    // Step 1: Fetch job description
    console.log(`[${nextJob.company}] Fetching job description...`)
    const jobDescription = await fetchJobDescription(nextJob.job_url, browserUseKey)
    nextJob.job_description = jobDescription

    // Step 2: Tailor resume for this specific job
    nextJob.current_step = 'Tailoring resume for this role...'
    console.log(`[${nextJob.company}] Tailoring resume...`)
    const baseResume = user.resume_text || request?.resume_text || ''
    const tailoredResume = await tailorResumeForJob(
      baseResume,
      jobDescription,
      nextJob.role,
      nextJob.company
    )
    nextJob.tailored_resume = tailoredResume

    // Step 3: Build application task with tailored resume
    nextJob.current_step = 'Starting application...'
    const task = buildApplicationTask(nextJob, user, tailoredResume)

    // Start browser-use task
    const response = await fetch('https://api.browser-use.com/api/v1/run-task', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${browserUseKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        task,
        save_browser_data: true
      })
    })

    if (!response.ok) {
      throw new Error('Failed to start application task')
    }

    const result = await response.json()
    nextJob.browser_use_task_id = result.id
    nextJob.live_url = result.live_url || null

    // Poll for application completion
    pollApplicationResult(session, nextJob, browserUseKey, supabase, user, request)

  } catch (error) {
    console.error('Application start error:', error)
    nextJob.status = 'failed'
    nextJob.error_message = error.message
    nextJob.completed_at = new Date().toISOString()

    // Process next job
    processNextJob(session, supabase, user, request)
  }
}

// Build application task for a specific job
function buildApplicationTask(job: BatchJob, user: PeeboUser, tailoredResume?: string): string {
  const resumeToUse = tailoredResume || user.resume_text || ''

  return `
Apply to the job at: ${job.job_url}

Applicant Information:
- Full Name: ${user.full_name || ''}
- Email: ${user.email}
- LinkedIn: ${user.linkedin_url || ''}

TAILORED RESUME (optimized for this specific role):
${resumeToUse.substring(0, 4000)}

Instructions:
1. Navigate to the job application page
2. Click the apply button
3. Fill in all required fields with the provided information
4. For resume field: If there's a text area or "enter manually" option, paste the TAILORED RESUME above
5. If only file upload is available, note this in your response
6. Answer screening questions based on the resume content
7. Submit the application
8. Confirm submission was successful

Report your progress at each step.
If there's a CAPTCHA or login required, report FAILURE with the reason.
At the end, report SUCCESS if the application was submitted, or FAILURE with the error.
`.trim()
}

// Poll for application completion
async function pollApplicationResult(
  session: BatchSession,
  job: BatchJob,
  apiKey: string,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser,
  request?: StartBatchRequest
) {
  const maxPolls = 120 // 10 minutes max per application
  let polls = 0

  while (polls < maxPolls) {
    await new Promise(resolve => setTimeout(resolve, 5000))
    polls++

    // Check if session was stopped
    if (session.status === 'stopped' || job.status === 'stopped') {
      return
    }

    try {
      const response = await fetch(`https://api.browser-use.com/api/v1/task/${job.browser_use_task_id}`, {
        headers: { 'Authorization': `Bearer ${apiKey}` }
      })

      if (!response.ok) continue

      const result = await response.json()

      // Update current step from task output
      if (result.steps?.length) {
        const lastStep = result.steps[result.steps.length - 1]
        job.current_step = lastStep.description || lastStep.action || 'Processing...'
      }

      // Update cost
      if (result.cost) {
        job.cost = result.cost
        session.total_cost = session.jobs.reduce((sum, j) => sum + (j.cost || 0), 0)
      }

      if (result.status === 'completed') {
        // Determine success from output
        const output = result.output?.toLowerCase() || ''
        const isSuccess = output.includes('success') || output.includes('submitted') || output.includes('applied')

        job.status = isSuccess ? 'success' : 'failed'
        job.agent_success = isSuccess
        job.completed_at = new Date().toISOString()

        if (!isSuccess) {
          job.error_message = result.output?.substring(0, 200) || 'Application failed'
        }

        // Add to tracker if successful
        if (isSuccess) {
          await addJobToTracker(job, supabase, user)
        }

        // Increment usage
        await supabase.rpc('increment_peebo_usage', { p_user_id: user.id })

        // Process next job
        processNextJob(session, supabase, user, request)
        return
      }

      if (result.status === 'failed') {
        job.status = 'failed'
        job.error_message = result.error || 'Task failed'
        job.completed_at = new Date().toISOString()

        processNextJob(session, supabase, user, request)
        return
      }
    } catch (error) {
      console.error('Polling error:', error)
    }
  }

  // Timeout
  job.status = 'failed'
  job.error_message = 'Application timed out'
  job.completed_at = new Date().toISOString()

  processNextJob(session, supabase, user, request)
}

// Add successful job to tracker
async function addJobToTracker(
  job: BatchJob,
  supabase: ReturnType<typeof createClient>,
  user: PeeboUser
) {
  try {
    // This would integrate with the tracker's jobs.json
    // For now, log it for manual sync
    await supabase.from('peebo_usage_logs').insert({
      user_id: user.id,
      action: 'batch_job_completed',
      job_url: job.job_url,
      metadata: {
        company: job.company,
        role: job.role,
        batch_job_id: job.id,
        cost: job.cost
      }
    })

    job.tracker_job_id = job.id // Use batch job ID as tracker reference
  } catch (error) {
    console.error('Failed to add job to tracker:', error)
  }
}
